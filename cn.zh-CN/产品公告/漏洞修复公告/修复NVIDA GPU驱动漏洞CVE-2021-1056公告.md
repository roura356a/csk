---
keyword: [NVIDA GPU驱动漏洞, CVE-2021-1056公告]
---

# 修复NVIDA GPU驱动漏洞CVE-2021-1056公告

NVIDIA近日公布了关于NVIDIA驱动的一个漏洞CVE-2021-1056。Kubernetes集群中存在阿里云GPU（EGS）的节点，如果客户自行安装或更新过节点上的NVIDIA GPU驱动，或者选择ACK集群默认安装的NVIDIA GPU驱动版本，都有可能存在该漏洞。本文介绍该漏洞的背景信息、影响范围和解决方案。

NVIDIA近日公布了关于NVIDIA GPU驱动的一个漏洞，该漏洞是NVIDIA GPU驱动程序与设备隔离相关的安全漏洞。当容器以非特权模式启动，攻击者利用这个漏洞，在容器中创建特殊的字符设备文件后，能够获取宿主机上所有GPU设备的访问权限。

关于漏洞的详细信息，请参见[CVE-2021-1056](https://nvidia.custhelp.com/app/answers/detail/a_id/5142)。

## 如何确认GPU节点NVIDIA驱动版本

登录到GPU节点，执行以下命令，查看驱动版本。

**说明：** 关于如何登录到GPU节点，请参见[通过密码认证登录Linux实例](/cn.zh-CN/实例/连接实例/使用VNC连接实例/通过密码认证登录Linux实例.md)和[通过密码认证登录Windows实例](/cn.zh-CN/实例/连接实例/使用VNC连接实例/通过密码认证登录Windows实例.md)。

```
nvidia-smi

Fri Apr 16 10:58:19 2021
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 418.87.01    Driver Version: 418.87.01    CUDA Version: 10.1     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla V100-SXM2...  On   | 00000000:00:07.0 Off |                    0 |
| N/A   34C    P0    37W / 300W |      0MiB / 16130MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
```

从上述输出的信息，可以知道该节点的GPU驱动版本为418.87.01。

## 影响范围

按照NVIDIA官方给出的漏洞说明信息，目前受影响的NVIDIA GPU驱动版本如下图所示。更多信息，请参见[NVIDIA官网](https://nvidia.custhelp.com/app/answers/detail/a_id/5142)。

![an19](https://static-aliyun-doc.oss-accelerate.aliyuncs.com/assets/img/zh-CN/1834558161/p262160.png)

-   如果您是自定义安装GPU驱动的，请参考上图确认您安装的GPU驱动是否受该漏洞影响。
-   阿里云容器服务Kubernetes版集群默认安装的NVIDIA GPU驱动也存在该漏洞。依据NVIDIA官方信息，目前已验证受影响的容器服务Kubernetes集群版本包括：
    -   ACK 1.16.9-aliyun.1（默认安装GPU驱动版本为418.87.01版本）
    -   ACK 1.18.8-aliyun.1（默认安装GPU驱动版本为418.87.01版本）

**说明：** 其他版本的ACK集群，GPU节点默认安装的NVIDIA GPU驱动，尚未出现在NVIDIA官方信息中。如果将来有新的官方信息变化，我们将及时跟进帮助您升级修复。

## 解决方案

**说明：** 升级节点GPU驱动的过程需要重启节点，节点上的业务将受到影响。

请您根据上图的NVIDIA官方信息，将节点升级到对应驱动版本进行漏洞修复：

-   如果节点驱动版本为390系列，请升级驱动至390.141版本。
-   如果节点驱动版本为418系列，请升级驱动至418.181.07版本。
-   如果节点驱动版本为450系列，请升级驱动至450.102.04版本。
-   如果节点驱动版本为460系列，请升级驱动至460.32.03版本。

关于升级ACK集群GPU节点驱动方法，请参见[通过节点池升级已有节点的NVIDIA驱动](/cn.zh-CN/Kubernetes集群用户指南/GPU/NPU/运维管理/通过节点池升级已有节点的NVIDIA驱动.md)、[手动升级GPU节点驱动](/cn.zh-CN/Kubernetes集群用户指南/GPU/NPU/运维管理/手动升级GPU节点驱动.md)和[通过节点池创建新NVIDIA驱动版本的节点](/cn.zh-CN/Kubernetes集群用户指南/GPU/NPU/运维管理/通过节点池创建新NVIDIA驱动版本的节点.md)。

**相关文档**  


[通过节点池升级已有节点的NVIDIA驱动](/cn.zh-CN/Kubernetes集群用户指南/GPU/NPU/运维管理/通过节点池升级已有节点的NVIDIA驱动.md)

[手动升级GPU节点驱动](/cn.zh-CN/Kubernetes集群用户指南/GPU/NPU/运维管理/手动升级GPU节点驱动.md)

[通过节点池创建新NVIDIA驱动版本的节点](/cn.zh-CN/Kubernetes集群用户指南/GPU/NPU/运维管理/通过节点池创建新NVIDIA驱动版本的节点.md)

