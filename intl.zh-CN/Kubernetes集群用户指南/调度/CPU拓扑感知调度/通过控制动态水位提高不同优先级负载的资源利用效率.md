---
keyword: [动态水位调节, 提升资源利用率, 控制QoS]
---

# 通过控制动态水位提高不同优先级负载的资源利用效率

为了充分利用节点资源，通常会将不同优先级的负载部署在同一节点上，且不同优先级负载在不同时间段占用的资源量不同。通过动态控制不同优先级的负载资源使用量及资源水位，可以提升负载的运行效率。本文主要介绍如何通过动态水位、定时任务CronJob及强隔离策略提高不同优先级负载的资源利用效率。

已安装resource-controller组件。更多信息，请参见[resource-controller](/intl.zh-CN/产品发布记录/组件介绍与变更记录/其他/resource-controller.md)。

为了充分利用节点资源，通常会将不同优先级的负载部署在同一节点上，比如高优先延迟敏感性（LS）和低优先尽力而为（BE）的负载。但是不同的负载往往具有不同的高峰期，不同时间段需要占用的资源量不一样。例如，高优先的延迟敏感型负载（LS）在白天资源量需求比较大，而在夜晚就比较少。

通过控制动态水位，可以在白天降低低优先BE类型负载的资源使用量，控制其资源水位，保证高优先LS类型负载的资源使用量（即QoS）。在夜晚可以提高低优先BE类型负载的资源使用量及资源水位，让其充分利用空闲资源，从而提高整体的资源利用率。

![动态水位控制](https://static-aliyun-doc.oss-accelerate.aliyuncs.com/assets/img/zh-CN/9410405261/p290429.png)

## 使用动态水位控制低优先级任务的使用资源量

1.  创建ConfigMap。

    1.  使用以下内容，创建resource-controller-config.yaml文件。

        ```
        apiVersion: v1
        kind: ConfigMap
        metadata:
          name: resource-controller-config
          namespace: kube-system
        data:
          default.qosClass: LS #LS（Latency Sensitive with High priority scheduing)、BE(Best Effort with Low priority scheduling).
          default.cpushare.qos.low.cpu-watermark: "50" # 25、50、100, set maximum water mark of workload of low qos.
          default.cpushare.qos.low.namespaces: "besteffort-ns1, besteffort-ns2" # By default NULL, suppress existing workload within specified namespaces immediately.
          default.cpushare.qos.high.force-reserved: "false" # By default false, true: turn on this switch to reserve dedicated CPUs for high priority tasks (LS).
        ```

        |参数|说明|
        |--|--|
        |default.cpushare.qos.low.cpu-watermark|表示低优先级任务可以占用整机资源的百分比。|
        |default.cpushare.qos.low.namespaces|表示需要控制的低优先级任务的命名空间。|
        |default.cpushare.qos.high.force-reserved|表示是否将高、低优先级的任务完全隔离，分别部署在不同的CPU上。该配置在创建之后生效，对于之前已经部署的任务，只对低优先级任务生效，高优先级任务保持不变。 |

    2.  执行以下命令创建ConfigMap。

        ```
        kubectl create -f resource-controller-config.yaml
        ```

2.  创建应用。

    本示例部署一个低优先级的计算Pi的任务，在`annotations`下打标。

    1.  使用以下内容，创建cal-pi.yaml文件。

        ```
        apiVersion: v1
        kind: Pod
        metadata:
          name: cal-pi
          annotations: 
            alibabacloud.com/qosClass: "BE" 
        spec:
          restartPolicy: Never
          containers:
          - image: registry.cn-zhangjiakou.aliyuncs.com/xianlu/java-pi
            name: cal-pi
            resources:
              requests:
                cpu: 4
              limits:
                cpu: 4  #需要设置resources.limit.cpu值。
            env:
            - name: limit
              value: "20000"
            - name: threadNum
              value: "3000"
        ```

        `alibabacloud.com/qosClass`表示该任务的性质：

        -   该字段的默认值在resource-controller-configmap.yaml的`default.qosClass`中设置，高优先延迟敏感性负载应设置为`LS`，低优先尽力而为类型负载应设置为`BE`。
        -   您也可以在以下场景中对该字段进行设置：
            -   Pod的`metadata`
            -   Deployment的`spec.metada`
            -   Daemonset、Statefulset或Job的`template.metadata`
    2.  执行以下命令创建应用。

        ```
        kubectl create -f cal-pi.yaml
        ```


## 使用CronJob分时策略控制低优先级任务的使用资源量

通过定时任务CronJob配置低优先级任务水位，即修改`schedule`（执行时间）和 `json`（配置文件）文件可以定时控制低优先级任务水位。

本示例，在早上七点以后高优先任务优先，把所有低优先BE任务动态压缩到CPU利用率为25%的水位。

1.  使用以下内容，创建mix-strategy-1.yaml文件。

    ```
    apiVersion: batch/v1beta1
    kind: CronJob
    metadata:
      name: mix-strategy-1
      namespace: kube-system
    spec:
      schedule: "0 7 * * *"
      jobTemplate:
        spec:
          completions: 1
          parallelism: 1
          template:
            spec:
              containers:
                - args:
                  - $(JSON_INPUT)
                  env:
                  - name: JSON_INPUT
                    value:
                       '{
                        "apiVersion":"v1",
                        "kind":"ConfigMap",
                        "metadata":{
                          "name":"resource-controller-config",
                          "namespace":"kube-system"
                        },
                        "data":{
                          "default.cpushare.qos.high.force-reserved": "false",
                          "default.cpushare.qos.low.cpu-watermark":"25",
                          "default.qosClass":"LS",
                          "default.cpushare.qos.low.namespaces": "low-qos-workload-namespace"
                        }
                        }
                      '
                  name: strategy
                  command: ["change-config"]
                  image: registry.cn-hangzhou.aliyuncs.com/shuangkun/change-config:v1
                  imagePullPolicy: Always
              serviceAccount: admin
              restartPolicy: OnFailure
    ```

2.  执行以下命令，创建定时任务。

    ```
    kubectl create -f mix-strategy-1.yaml
    ```


同样的，可以通过定时任务设置其他低优先级任务在任何时间段的水位，进而提高整体资源利用率。

## 使用强隔离策略控制任务的使用资源量

当低优先级任务的CPU利用率低于50%，且高优先级任务的CPU利用率也低于50%时，推荐使用强制隔离。配置参数`default.cpushare.qos.high.force-reserved`为`true`，配置`default.cpushare.qos.low.cpu-watermark`为50，将高、低优先级任务分隔在不同的NUMA和CCX上，能为高优先任务提供更好的性能环境。

1.  使用以下内容，修改resource-controller-config.yaml文件。

    ```
    apiVersion: v1
    kind: ConfigMap
    metadata:
      name: resource-controller-config
      namespace: kube-system
    data:
      default.qosClass: LS #LS（Latency Sensitive with High priority scheduing)、BE(Best Effort with Low priority scheduling)
      default.cpushare.qos.low.cpu-watermark: "50" # 25、50、100, set maximum water mark of workload of low qos
      default.cpushare.qos.low.namespaces: "besteffort-ns1, besteffort-ns2" # By default NULL, suppress existing workload within specified namespaces immediately.
      default.cpushare.qos.high.force-reserved: "true" # By default false, true: turn on this switch to reserve dedicated CPUs for high priority tasks (LS)
    ```

2.  执行以下命令修改ConfigMap。

    ```
    kubectl apply -f resource-controller-config.yaml
    ```


